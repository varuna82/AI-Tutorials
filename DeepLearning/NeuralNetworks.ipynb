{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "# Components of a Neural Network\n",
    "- Input Layer\n",
    "- Hidden Layer\n",
    "- Output Layer\n",
    "- Activation Function\n",
    "- Loss Function\n",
    "- Gradient Descent\n",
    "- Executing Gradient Descent\n",
    "- Monitoring Bias/Variance\n",
    "- Hyper parameter optimization\n",
    "\n",
    "Note: DNNs have more than 2 hidden layers.\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost (Loss/Error) Function\n",
    "- Calculate the distance between labels and predictions\n",
    "- Used to calculate direction of the gradient descent.\n",
    "- Error function should be differentiable.\n",
    "- Error function should be continuous.\n",
    "\n",
    "There are various error functions and should be chosen according to the situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vOorS9ODFvJi"
   },
   "source": [
    "### Error Function (Loglikelihood Cross-entropy)\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "Error(model, dataset) = -\\frac{1}{N}\\sum_{i=0}^{N} \\sum_{j=0}^{M} y^{(i)}_j * ln(\\hat y^{(i)}_j) \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "**Questions**\n",
    "- Are there other error functions than this one \n",
    "\n",
    "Justification for deriving the **error function** is given below.\n",
    "\n",
    "#### Error Count\n",
    "- Count number of errors\n",
    "- Problems\n",
    "  - Cost function is discrete, it's difficult for the gradient descent to work in small steps\n",
    "<img src=\"DescreetError.png\" width=\"200px\"> \n",
    "\n",
    "#### Log Loss Function\n",
    "- Estimate error based on distance between labels and predictions\n",
    "  - Hence, larger penalty will be assigned for miss predictions and smaller penalty for better predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Likelihood\n",
    "\n",
    "- [Udacity Lecture for likelihood](https://classroom.udacity.com/nanodegrees/nd889/parts/16cf5df5-73f0-4afa-93a9-de5974257236/modules/6124bd95-dec2-44f9-bf3b-498ea57699c7/lessons/47f6c25c-7749-4a02-b807-7a5b37f362e8/concepts/32704510-a70c-4a9b-a2c6-77ccdd389c0c)\n",
    "- [Udacity Lecture for log likelihood resoning](https://classroom.udacity.com/nanodegrees/nd889/parts/16cf5df5-73f0-4afa-93a9-de5974257236/modules/6124bd95-dec2-44f9-bf3b-498ea57699c7/lessons/47f6c25c-7749-4a02-b807-7a5b37f362e8/concepts/2098790c-e2ce-4c0e-9e39-326bf189b417)\n",
    "- Likelihood is probability for accuracy of the predictions.\n",
    "   - Predictions are given as probabilities for being class 1 -> ŷ\n",
    "   - Labels are given as 1 or 0 (since this is the binary-class) -> y\n",
    "   \n",
    "   $$Likelihood = \\prod_{n=0}^{N} y_n * \\hat y_n + (1 - y_n) * (1 - \\hat y_n)$$\n",
    "   ----- or ----\n",
    "   $$Likelihood = \\prod_{n=0}^{N} {\\hat y_n}^{y_n} * {(1 - \\hat y_n)}^{(1 - y_n)}$$\n",
    "   \n",
    "- Likelihood is difficult to work with, since product of probabilities get very small \n",
    "(product of fractions gets small exponetially)\n",
    "\n",
    "#### Cross-Entropy\n",
    "\n",
    "$$Crossentropy = -\\sum_{i=0}^{N} ln(y^i_{label} * y^i_{pred}) + ln((1 - y^i_{label}) * (1 - y^i_{pred}))$$\n",
    "\n",
    "- **Log (ln)** is used to convert products in the likelihood into summations.\n",
    "- **Negative** is used since likelihood is a probability (0 < p < 1), therefore log value is a minus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  0.6 1.  0.2]\n",
      "Labels       : 0.0, 1.0, 0.0, 1.0\n",
      "Prediction   : 0.9, 0.6, 0.3, 0.2 (predicted probability of being 1)\n",
      "Likelihoods  : 0.1, 0.6, 0.7, 0.2 (predicted probability of being labeled class)\n",
      "Likelihood   : 0.0084\n",
      "Cross-entropy: 4.7795\n"
     ]
    }
   ],
   "source": [
    "# example in udacity lecture worked out\n",
    "\n",
    "y_labels = tf.constant([0., 1., 0., 1.]) # class labels \n",
    "y_pred = tf.constant([0.9, 0.6, 0.3, 0.2]) # probability of being 1\n",
    "\n",
    "term_1 = tf.pow(y_pred, y_labels)\n",
    "term_2 = tf.pow((1-y_pred), (1-y_labels))\n",
    "likelihoods = term_1 * term_2\n",
    "likelihood = tf.reduce_prod(likelihoods)\n",
    "\n",
    "log_likelihoods = -tf.log(likelihoods)\n",
    "cross_entropy = tf.reduce_sum(log_likelihoods)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    _y_labels, _y_preds = sess.run([y_labels, y_pred])\n",
    "    _likelihood, _likelihoods, _term_1, _term_2 = sess.run([likelihood, likelihoods, term_1, term_2])\n",
    "    _cross_entropy, _log_likelihoods = sess.run([cross_entropy, log_likelihoods])\n",
    "    \n",
    "    print(sess.run(tpow))\n",
    "\n",
    "def flist(l):\n",
    "    return \", \".join([f\"{x:.1f}\" for x in l])\n",
    "print(f\"Labels       : {flist(_y_labels)}\")\n",
    "print(f\"Prediction   : {flist(_y_preds)} (predicted probability of being 1)\")\n",
    "print(f\"Likelihoods  : {flist(_likelihoods)} (predicted probability of being labeled class)\")\n",
    "print(f\"Likelihood   : {_likelihood:.4f}\")\n",
    "print(f\"Cross-entropy: {_cross_entropy:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Entropy (Multi-class)\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "Crossentropy = -\\sum_{i=0}^{N} \\sum_{j=0}^{M} y^{(i)}_j * ln(\\hat y^{(i)}_j) \\\\\n",
    "\\end{align}\n",
    "$\n",
    "- Legend\n",
    "  - i: number of data points (1 to N)\n",
    "  - j: number of classes (1 to M)\n",
    "  - y: labels\n",
    "  - ŷ: predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Function\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "Error(model, dataset) = -\\frac{1}{N}\\sum_{i=0}^{N} \\sum_{j=0}^{M} y^{(i)}_j * ln(\\hat y^{(i)}_j) \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "- Legend\n",
    "  - i: number of data points (1 to N)\n",
    "  - j: number of classes (1 to M)\n",
    "  - y: labels\n",
    "  - ŷ: predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Loss Functions\n",
    "\n",
    "- [absolute difference](https://www.tensorflow.org/api_docs/python/tf/losses/absolute_difference): Average difference between two vectors\n",
    "- [sigmoid_cross_entropy_loss](https://www.tensorflow.org/api_docs/python/tf/losses/sigmoid_cross_entropy): Take *logits* for *y_pred*. i.e. values from the output layer before calculating probabilities; in other words, **before applying *sigmoid* function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute difference\n",
      "Numpy:  2.5\n",
      "Tensorflow 2.5\n",
      "\n",
      "Log Loss:  -1.6118101\n",
      "MSE Loss:  2.5\n",
      "Sigmoid Cross Entropy Loss:  0.782784\n"
     ]
    }
   ],
   "source": [
    "# example in udacity lecture worked out\n",
    "\n",
    "y_labels = tf.constant([0., 1., 0., 1.]) # class labels \n",
    "y_pred = tf.constant([0.9, 0.6, 0.3, 0.2]) # probability of being 1\n",
    "\n",
    "log_loss = tf.losses.log_loss([1.1], [1])\n",
    "mse_loss = tf.losses.mean_squared_error([1, 2], [2, 4])\n",
    "absolute_loss = tf.losses.absolute_difference([1, -2], [2, 2])\n",
    "sigmoid_cross_entropy_loss = tf.losses.sigmoid_cross_entropy(y_labels, y_pred)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    print(\"Absolute difference\")\n",
    "    _absolute_loss = sess.run(absolute_loss)\n",
    "    print(\"Numpy: \", np.abs(np.average(np.array([1, -2]) - np.array([2, 2]))))\n",
    "    print(\"Tensorflow\", _absolute_loss)\n",
    "    print()\n",
    "    print(\"Log Loss: \", sess.run(log_loss))\n",
    "    print(\"MSE Loss: \", sess.run(mse_loss))\n",
    "    print(\"Sigmoid Cross Entropy Loss: \", sess.run(sigmoid_cross_entropy_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Function\n",
    "$$sigmoid(x) = \\dfrac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#x = tf.get_variable(\"X\")\n",
    "x = tf.range(-8, 8, 0.1)\n",
    "y = tf.sigmoid(x)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    X, Y = sess.run([x, y])\n",
    "\n",
    "plt.title(\"Sigmoid\")\n",
    "plt.plot(X, Y)\n",
    "plt.yticks(np.arange(0, 1.1, 0.25))\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert descrete prediction (0 or 1) to a continuous function. Continuous functions provide better estimates for the loss function.\n",
    "\n",
    "**Usage**\n",
    "- Activation function of the hidden layers.\n",
    "  - Explain how Relu is better\n",
    "- Activation function for the output layer in binary classification.\n",
    "  - Explain how continous function is converted to descrete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "\n",
    "$$Softmax(i)=\\dfrac{e^{L_i}}{\\sum_{i=1}^{N} e^{L_i}}$$ \n",
    "`Where`<br>\n",
    "`- i: class`<br>\n",
    "`- L_i: Linear fuction score for class i`\n",
    "\n",
    "- Softmax converts score given to each class into probabilities that sums upto 1.\n",
    "- Used as activation function for output layer in multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:                [2. 3. 1.]\n",
      "Softmax Probabilities: [0.24472848 0.66524094 0.09003057]\n",
      "Sum:                   1.0\n"
     ]
    }
   ],
   "source": [
    "#x = tf.get_variable(\"X\")\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.nn.softmax(x)\n",
    "\n",
    "sum = tf.reduce_sum(y)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    Sum, X, Y = sess.run([sum, x, y], feed_dict={x: [2, 3, 1]})\n",
    "\n",
    "print(f\"Scores:                {X}\")\n",
    "print(f\"Softmax Probabilities: {Y}\")\n",
    "print(f\"Sum:                   {Sum}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Neural Networks.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
